**The paper list for language based visual trackers**

[Note] Please submit an issue, if you find more related papers on this direction. 

[1]. **Tracking by natural language specification**
[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017: 6495-6503. Li Z, Tao R, Gavves E, et al. 
[[Paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Tracking_by_Natural_CVPR_2017_paper.pdf)] [[Code](https://github.com/zhenyangli/lang-tracker)]

[2]. **Describe and attend to track: Learning natural language guided structural representation and visual attention for object tracking**[J]. 
Wang X, Li C, Yang R, et al. 
arXiv preprint arXiv:1811.10014, 2018.
[[Paper](https://arxiv.org/pdf/1811.10014)] 

[3]. [Benchmark-Dataset] **Lasot: A high-quality benchmark for large-scale single object tracking**
[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019: 5374-5383.
Fan H, Lin L, Yang F, et al. 
[[Paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Fan_LaSOT_A_High-Quality_Benchmark_for_Large-Scale_Single_Object_Tracking_CVPR_2019_paper.pdf)] 
[[Project](http://vision.cs.stonybrook.edu/~lasot/)] 
[[Journal-Version](https://link.springer.com/article/10.1007/s11263-020-01387-y)]

[4]. [Benchmark-Dataset] **Towards More Flexible and Accurate Object Tracking with Natural Language: Algorithms and Benchmark,**
[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 13763-13773.
Wang X, Shu X, Zhang Z, et al. 
[[Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Towards_More_Flexible_and_Accurate_Object_Tracking_With_Natural_Language_CVPR_2021_paper.pdf)]
[[Eval-Toolkit](https://sites.google.com/view/langtrackbenchmark/)]
[[Project](https://github.com/wangxiao5791509/TNL2K_evaluation_toolkit)]

[5]. **Grounding-tracking-integration**[J]. 
Yang Z, Kumar T, Chen T, et al. 
IEEE Transactions on Circuits and Systems for Video Technology, 2020.
[[Paper](https://ieeexplore.ieee.org/abstract/document/9261416/)]


[6]. **Capsule-based Object Tracking with Natural Language Specification**, 
ACM-MM '21: Proceedings of the 29th ACM International Conference on MultimediaOctober 2021, 
Ding Ma, Xiangqian Wu [[Paper](https://dl.acm.org/doi/abs/10.1145/3474085.3475349)] 

[7] **Siamese Natural Language Tracker: Tracking by Natural Language Descriptions With Siamese Trackers**, 
Qi Feng, Vitaly Ablavsky, Qinxun Bai, Stan Sclaroff; 
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021, pp. 5851-5860
[[Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Feng_Siamese_Natural_Language_Tracker_Tracking_by_Natural_Language_Descriptions_With_CVPR_2021_paper.pdf)]
[[Code](https://github.com/fredfung007/snlt)]

[8] **Siamese Tracking with Lingual Object Constraints.**
Filtenborg, Maximilian, Efstratios Gavves, and Deepak Gupta. 
arXiv preprint arXiv:2011.11721 (2020).
[[Paper](https://arxiv.org/pdf/2011.11721.pdf)]
[[Code](https://github.com/CMFiltenborg/lingually_constrained_tracking)] 

[9] **Real-time visual object tracking with natural language description**, 
[C]//Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 2020: 700-709.
Feng Q, Ablavsky V, Bai Q, et al. 
[[Paper](http://openaccess.thecvf.com/content_WACV_2020/html/Feng_Real-time_Visual_Object_Tracking_with_Natural_Language_Description_WACV_2020_paper.html)]

[10] **WebUAV-3M: A Benchmark Unveiling the Power of Million-Scale Deep UAV Tracking**, 
Chunhui Zhang, Guanjie Huang, Li Liu, Shan Huang, Yinan Yang, Yuxuan Zhang, Xiang Wan, Shiming Ge, 
[[Paper](https://arxiv.org/pdf/2201.07425.pdf)] 
[[Github](https://github.com/983632847/WebUAV-3M)]

[11] **Cityflow-nl: Tracking and retrieval of vehicles at city scale by natural language descriptions**[J]. 
Feng Q, Ablavsky V, Sclaroff S. arXiv preprint arXiv:2101.04741, 2021.
[[Paper](https://arxiv.org/pdf/2101.04741.pdf)]
[[Dataset](https://github.com/fredfung007/cityflow-nl)]

[12] **SBNet: Segmentation-based Network for Natural Language-based Vehicle Search**
Lee S, Woo T, Lee S H. [C]//Proceedings of the IEEE/CVF CVPR Workshop. 2021: 4054-4060.
[[Paper](https://openaccess.thecvf.com/content/CVPR2021W/AICity/papers/Lee_SBNet_Segmentation-Based_Network_for_Natural_Language-Based_Vehicle_Search_CVPRW_2021_paper.pdf)]
[[Code](https://github.com/lsrock1/nlp_search)]

[13] **Spatio-temporal person retrieval via natural language queries**[C] 
Yamaguchi M, Saito K, Ushiku Y, et al. //Proceedings of the IEEE International Conference on Computer Vision. 2017: 1453-1462.
[[Paper](https://openaccess.thecvf.com/content_ICCV_2017/papers/Yamaguchi_Spatio-Temporal_Person_Retrieval_ICCV_2017_paper.pdf)] 
[[project](https://www.mi.t.u-tokyo.ac.jp/projects/person_search)] 

[14] **Person tube retrieval via language description**[C]
Fan H, Yang Y. //Proceedings of the AAAI Conference on Artificial Intelligence. 2020, 34(07): 10754-10761.
[[Paper](https://ojs.aaai.org/index.php/AAAI/article/download/6704/6558)] 

[15] **Weakly-Supervised Spatio-Temporally Grounding Natural Sentence in Video**, 
Chen Z, Ma L, Luo W, et al. [C]//Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. 2019: 1884-1894. 
[[Paper](https://arxiv.org/pdf/1906.02549.pdf)]
[[Dataset & Code](https://github.com/zfchenUnique/WSSTG)]
 
[16] **Referring to Objects in Videos Using Spatio-Temporal Identifying Descriptions**[C]
Wiriyathammabhum P, Shrivastava A, Morariu V, et al. //Proceedings of the Second Workshop on Shortcomings in Vision and Language. 2019: 14-25. 
[[Paper](https://arxiv.org/pdf/1904.03885.pdf)] 

[17] **Stvgbert: A visual-linguistic transformer based framework for spatio-temporal video grounding**[C]
Su R, Yu Q, Xu D. //Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021: 1533-1542. 
[[Paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Su_STVGBert_A_Visual-Linguistic_Transformer_Based_Framework_for_Spatio-Temporal_Video_Grounding_ICCV_2021_paper.pdf)] 

[18] **Connecting language and vision for natural language-based vehicle retrieval**[C]
Bai S, Zheng Z, Wang X, et al. //Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 4034-4043. 
[[Paper](https://openaccess.thecvf.com/content/CVPR2021W/AICity/papers/Bai_Connecting_Language_and_Vision_for_Natural_Language-Based_Vehicle_Retrieval_CVPRW_2021_paper.pdf)] 
[[Code](https://github.com/ShuaiBai623/AIC2021-T5-CLV)]

[19] "**Semantics-aware spatial-temporal binaries for cross-modal video retrieval**." 
Qi, Mengshi, et al. IEEE Transactions on Image Processing 30 (2021): 2989-3004.
[[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9351755)]


[20] Song, Sijie, et al. "**Co-Grounding Networks with Semantic Attention for Referring Expression Comprehension in Videos.**" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021. [[Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Song_Co-Grounding_Networks_With_Semantic_Attention_for_Referring_Expression_Comprehension_in_CVPR_2021_paper.pdf)] [[Code](https://github.com/SijieSong/CVPR21-Cogrounding_semantic_attention)]

[21] [NeuIPS-2022] **Divert more attention to vision-language tracking**. Guo, M., Zhang, Z., Fan, H., & Jing, L. (2022).  Advances in Neural Information Processing Systems, 35, 4446-4460., 
[[arXiv](https://arxiv.org/abs/2207.01076)] 
[[Code](https://github.com/JudasDie/SOTS)]

[22] Li, Yihao, et al. "**Cross-Modal Target Retrieval for Tracking by Natural Language.**" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022. [[Paper](https://openaccess.thecvf.com/content/CVPR2022W/ODRUM/papers/Li_Cross-Modal_Target_Retrieval_for_Tracking_by_Natural_Language_CVPRW_2022_paper.pdf)]

[23] **BAPO: A Large-Scale Multimodal Corpus for Ball Possession Prediction in American Football Games**, Ziruo Yi, Eduardo Blanco, Heng Fan, Mark V. Albert, 2022 IEEE 5th International Conference on Multimedia Information Processing and Retrieval (MIPR)
 [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9874586)]  
 
[24] [PRL-2023] **Transformer vision-language tracking via proxy token guided cross-modal fusion. Pattern Recognition Letters**, Zhao, H., Wang, X., Wang, D., Lu, H., & Ruan, X. (2023). 168, 10-16.
[[Paper](https://www.sciencedirect.com/science/article/pii/S0167865523000545)] 

[25] [CVPR-2023] **Joint Visual Grounding and Tracking with Natural Language Specification.** Zhou, L., Zhou, Z., Mao, K., & He, Z. (2023).  In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 23151-23160).  
[[Paper](https://arxiv.org/pdf/2303.12027.pdf)]
[[Code](https://github.com/lizhou-cs/JointNLT)]

[26] **Type-to-Track: Retrieve Any Object via Prompt-based Tracking**, Pha Nguyen, Kha Gia Quach, Kris Kitani, Khoa Luu 
[[Paper](https://arxiv.org/pdf/2305.13495.pdf)] 

[27] [IEEE TMM 2023] "**One-stream Vision-Language Memory Network for Object Tracking**," H. Zhang, J. Wang, J. Zhang, T. Zhang and B. Zhong,  in IEEE Transactions on Multimedia, doi: 10.1109/TMM.2023.3285441. [[Paper](https://ieeexplore.ieee.org/abstract/document/10149530)] 

[28] [ACM MM-2023] **All in One: Exploring Unified Vision-Language Tracking with Multi-Modal Alignment**, Chunhui Zhang, Xin Sun, Li Liu, Member, IEEE, Yiqian Yang, Qiong Liu, Xi Zhou, Yanfeng Wang 
[[Paper](https://arxiv.org/pdf/2307.03373.pdf)] 

[29] [IEEE TCSVT 2023] **Towards Unified Token Learning for Vision-Language Tracking**, Yaozong Zheng, Bineng Zhong, Qihua Liang, Guorong Li, Rongrong Ji, Xianxian Li, IEEE TCSVT 2023, [[Paper](https://ieeexplore.ieee.org/abstract/document/10208210)] 

[30] [ICCV-2023] **CiteTracker: Correlating Image and Text for Visual Tracking**, Xin Li, Yuqing Huang, Zhenyu He, Yaowei Wang, Huchuan Lu, Ming-Hsuan Yang [[Paper](https://arxiv.org/pdf/2308.11322.pdf)] [[Code](https://github.com/NorahGreen/CiteTracker)] 

[31] [arXiv-2023] **Divert More Attention to Vision-Language Object Tracking**. Guo, M., Zhang, Z., Jing, L., Ling, H., & Fan, H. (2023).  arXiv preprint arXiv:2307.10046. [[Paper](https://arxiv.org/pdf/2307.10046.pdf)] 

[32] [AAAI-2024] **Unifying Visual and Vision-Language Tracking via Contrastive Learning**, Yinchao Ma1, Yuyang Tang1, Wenfei Yang1, Tianzhu Zhang1*, Jinpeng Zhang2, Mengxue Kang [[Paper](https://arxiv.org/pdf/2401.11228.pdf)] [[Code](https://github.com/OpenSpaceAI/UVLTrack)]

[33] **VastTrack: Vast Category Visual Object Tracking**, Liang Peng, Junyuan Gao, Xinran Liu, Weihong Li, Shaohua Dong, Zhipeng Zhang, Heng Fan, Libo Zhang
  [[Paper](https://arxiv.org/abs/2403.03493)] 

[34] **Beyond MOT: Semantic Multi-Object Tracking**, Yunhao Li, Hao Wang, Qin Li, Xue Ma, Jiali Yao, Shaohua Dong, Heng Fan, Libo Zhang 
 [[Paper](https://arxiv.org/abs/2403.05021)] 

[35] [IEEE TCSVT] G. Zhang, B. Zhong, Q. Liang, Z. Mo, N. Li and S. Song, "**One-Stream Stepwise Decreasing for Vision-Language Tracking**," in IEEE Transactions on Circuits and Systems for Video Technology, doi: 10.1109/TCSVT.2024.3395352. 
 [[Paper](https://ieeexplore.ieee.org/abstract/document/10510485)] 

[36] [CVPR Workshop] **DTLLM-VLT: Diverse Text Generation for Visual Language Tracking Based on LLM**, arXiv:2405.12139, CVPR Workshop 2024, Oral Presentation, Xuchen Li, Xiaokun Feng, Shiyu Hu, Meiqi Wu, Dailing Zhang, Jing Zhang, Kaiqi Huang 
 [[Paper](https://arxiv.org/abs/2405.12139)] 
 


















































