**The paper list for language based visual trackers**

[Note] Please submit an issue, if you find more related papers on this direction. 

[1]. **Tracking by natural language specification**
[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017: 6495-6503. Li Z, Tao R, Gavves E, et al. 
[[Paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Tracking_by_Natural_CVPR_2017_paper.pdf)] [[Code](https://github.com/zhenyangli/lang-tracker)]

[2]. **Describe and attend to track: Learning natural language guided structural representation and visual attention for object tracking**[J]. 
Wang X, Li C, Yang R, et al. 
arXiv preprint arXiv:1811.10014, 2018.
[[Paper](https://arxiv.org/pdf/1811.10014)] 

[3]. [Benchmark-Dataset] **Lasot: A high-quality benchmark for large-scale single object tracking**
[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019: 5374-5383.
Fan H, Lin L, Yang F, et al. 
[[Paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Fan_LaSOT_A_High-Quality_Benchmark_for_Large-Scale_Single_Object_Tracking_CVPR_2019_paper.pdf)] 
[[Project](http://vision.cs.stonybrook.edu/~lasot/)] 
[[Journal-Version](https://link.springer.com/article/10.1007/s11263-020-01387-y)]

[4]. [Benchmark-Dataset] **Towards More Flexible and Accurate Object Tracking with Natural Language: Algorithms and Benchmark,**
[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 13763-13773.
Wang X, Shu X, Zhang Z, et al. 
[[Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Towards_More_Flexible_and_Accurate_Object_Tracking_With_Natural_Language_CVPR_2021_paper.pdf)]
[[Eval-Toolkit](https://sites.google.com/view/langtrackbenchmark/)]
[[Project](https://github.com/wangxiao5791509/TNL2K_evaluation_toolkit)]

[5]. **Grounding-tracking-integration**[J]. 
Yang Z, Kumar T, Chen T, et al. 
IEEE Transactions on Circuits and Systems for Video Technology, 2020.
[[Paper](https://ieeexplore.ieee.org/abstract/document/9261416/)]


[6]. **Capsule-based Object Tracking with Natural Language Specification**, 
ACM-MM '21: Proceedings of the 29th ACM International Conference on MultimediaOctober 2021, 
Ding Ma, Xiangqian Wu [[Paper](https://dl.acm.org/doi/abs/10.1145/3474085.3475349)] 

[7] **Siamese Natural Language Tracker: Tracking by Natural Language Descriptions With Siamese Trackers**, 
Qi Feng, Vitaly Ablavsky, Qinxun Bai, Stan Sclaroff; 
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021, pp. 5851-5860
[[Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Feng_Siamese_Natural_Language_Tracker_Tracking_by_Natural_Language_Descriptions_With_CVPR_2021_paper.pdf)]
[[Code](https://github.com/fredfung007/snlt)]

[8] **Siamese Tracking with Lingual Object Constraints.**
Filtenborg, Maximilian, Efstratios Gavves, and Deepak Gupta. 
arXiv preprint arXiv:2011.11721 (2020).
[[Paper](https://arxiv.org/pdf/2011.11721.pdf)]
[[Code](https://github.com/CMFiltenborg/lingually_constrained_tracking)] 

[9] **Real-time visual object tracking with natural language description**, 
[C]//Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 2020: 700-709.
Feng Q, Ablavsky V, Bai Q, et al. 
[[Paper](http://openaccess.thecvf.com/content_WACV_2020/html/Feng_Real-time_Visual_Object_Tracking_with_Natural_Language_Description_WACV_2020_paper.html)]

[10] **WebUAV-3M: A Benchmark Unveiling the Power of Million-Scale Deep UAV Tracking**, 
Chunhui Zhang, Guanjie Huang, Li Liu, Shan Huang, Yinan Yang, Yuxuan Zhang, Xiang Wan, Shiming Ge, 
[[Paper](https://arxiv.org/pdf/2201.07425.pdf)] 
[[Github](https://github.com/983632847/WebUAV-3M)]

[11] **Cityflow-nl: Tracking and retrieval of vehicles at city scale by natural language descriptions**[J]. 
Feng Q, Ablavsky V, Sclaroff S. arXiv preprint arXiv:2101.04741, 2021.
[[Paper](https://arxiv.org/pdf/2101.04741.pdf)]
[[Dataset](https://github.com/fredfung007/cityflow-nl)]

[12] **SBNet: Segmentation-based Network for Natural Language-based Vehicle Search**
Lee S, Woo T, Lee S H. [C]//Proceedings of the IEEE/CVF CVPR Workshop. 2021: 4054-4060.
[[Paper](https://openaccess.thecvf.com/content/CVPR2021W/AICity/papers/Lee_SBNet_Segmentation-Based_Network_for_Natural_Language-Based_Vehicle_Search_CVPRW_2021_paper.pdf)]
[[Code](https://github.com/lsrock1/nlp_search)]

[13] **Spatio-temporal person retrieval via natural language queries**[C] 
Yamaguchi M, Saito K, Ushiku Y, et al. //Proceedings of the IEEE International Conference on Computer Vision. 2017: 1453-1462.
[[Paper](https://openaccess.thecvf.com/content_ICCV_2017/papers/Yamaguchi_Spatio-Temporal_Person_Retrieval_ICCV_2017_paper.pdf)] 
[[project](https://www.mi.t.u-tokyo.ac.jp/projects/person_search)] 

[14] **Person tube retrieval via language description**[C]
Fan H, Yang Y. //Proceedings of the AAAI Conference on Artificial Intelligence. 2020, 34(07): 10754-10761.
[[Paper](https://ojs.aaai.org/index.php/AAAI/article/download/6704/6558)] 

[15] **Weakly-Supervised Spatio-Temporally Grounding Natural Sentence in Video**, 
Chen Z, Ma L, Luo W, et al. [C]//Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. 2019: 1884-1894. 
[[Paper](https://arxiv.org/pdf/1906.02549.pdf)]
[[Dataset & Code](https://github.com/zfchenUnique/WSSTG)]
 
[16] **Referring to Objects in Videos Using Spatio-Temporal Identifying Descriptions**[C]
Wiriyathammabhum P, Shrivastava A, Morariu V, et al. //Proceedings of the Second Workshop on Shortcomings in Vision and Language. 2019: 14-25. 
[[Paper](https://arxiv.org/pdf/1904.03885.pdf)] 

[17] **Stvgbert: A visual-linguistic transformer based framework for spatio-temporal video grounding**[C]
Su R, Yu Q, Xu D. //Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021: 1533-1542. 
[[Paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Su_STVGBert_A_Visual-Linguistic_Transformer_Based_Framework_for_Spatio-Temporal_Video_Grounding_ICCV_2021_paper.pdf)] 

[18] **Connecting language and vision for natural language-based vehicle retrieval**[C]
Bai S, Zheng Z, Wang X, et al. //Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 4034-4043. 
[[Paper](https://openaccess.thecvf.com/content/CVPR2021W/AICity/papers/Bai_Connecting_Language_and_Vision_for_Natural_Language-Based_Vehicle_Retrieval_CVPRW_2021_paper.pdf)] 
[[Code](https://github.com/ShuaiBai623/AIC2021-T5-CLV)]

[19] "**Semantics-aware spatial-temporal binaries for cross-modal video retrieval**." 
Qi, Mengshi, et al. IEEE Transactions on Image Processing 30 (2021): 2989-3004.
[[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9351755)]


[20] Song, Sijie, et al. "**Co-Grounding Networks with Semantic Attention for Referring Expression Comprehension in Videos.**" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021. [[Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Song_Co-Grounding_Networks_With_Semantic_Attention_for_Referring_Expression_Comprehension_in_CVPR_2021_paper.pdf)] [[Code](https://github.com/SijieSong/CVPR21-Cogrounding_semantic_attention)]

[21] Mingzhe Guo, Zhipeng Zhang, Heng Fan, Liping Jing, **Divert More Attention to Vision-Language Tracking**, [[arXiv](https://arxiv.org/abs/2207.01076)] 

[22] Li, Yihao, et al. "**Cross-Modal Target Retrieval for Tracking by Natural Language.**" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022. [[Paper](https://openaccess.thecvf.com/content/CVPR2022W/ODRUM/papers/Li_Cross-Modal_Target_Retrieval_for_Tracking_by_Natural_Language_CVPRW_2022_paper.pdf)]

[23] **BAPO: A Large-Scale Multimodal Corpus for Ball Possession Prediction in American Football Games**, Ziruo Yi, Eduardo Blanco, Heng Fan, Mark V. Albert, 2022 IEEE 5th International Conference on Multimedia Information Processing and Retrieval (MIPR)
 [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9874586)]  
 
[24] Zhao, Haojie, et al. "**Transformer Vision-Language Tracking via Proxy Token Guided Cross-Modal Fusion**." Pattern Recognition Letters (2023).  
[[Paper](https://www.sciencedirect.com/science/article/pii/S0167865523000545)] 

[25] **Joint Visual Grounding and Tracking with Natural Language Specification**, Li Zhou, Zikun Zhou, Kaige Mao, and Zhenyu He 
[[Paper](https://arxiv.org/pdf/2303.12027.pdf)]
[[Code](https://github.com/lizhou-cs/JointNLT)]

[26] **Type-to-Track: Retrieve Any Object via Prompt-based Tracking**, Pha Nguyen, Kha Gia Quach, Kris Kitani, Khoa Luu 
[[Paper](https://arxiv.org/pdf/2305.13495.pdf)]

[27] 






















































